//============================================================================//
// Define params
//============================================================================//

// Input and output
params.out_dir = "output"
params.reads = "raw_data/*fastq"

// SPAdes
params.spades_type = "meta"
params.temp_dir = "temp"

// DIAMOND
params.diamond_database = "/n/data2/dfci/medonc/decaprio/jason/\
genomes_indexes_references_databases/diamond_databases/ALL_SMALL80_NH.dmnd"
params.diamond_evalue = "10"
params.diamond_outfmt = "6 qseqid stitle sseqid staxids evalue bitscore pident length"

// BLAST
params.blast_database = "/n/data2/dfci/medonc/decaprio/jason/\
genomes_indexes_references_databases/blastn_databases/nt_v5/nt_v5"
params.blast_evalue = 10
params.blast_type = 'megablast'
params.blast_outfmt = "6 qseqid stitle sseqid staxid evalue bitscore pident length"
params.blast_log_file = "blast.log"
params.blast_max_hsphs = 1
params.blast_max_targets = 30
params.blast_restrict_to_taxids = "no"
params.blast_ignore_taxids = "no"

// BLAST/DIAMOND Conversion
params.LCA_top_percent = 1
params.within_percent_of_top_score = 1
params.taxid_blacklist = "$VID/resources/2019-08-09_blacklist.tsv"
params.diamond_readable_colnames = "query_ID seq_title seq_ID taxonID evalue bitscore pident length"
params.blast_readable_colnames = "query_ID seq_title seq_ID taxonID evalue bitscore pident length"
params.taxonomy_column = "taxonID"
params.score_column = "bitscore"

// Contaminant blast search
params.blast_contaminant_database = "/n/data2/dfci/medonc/decaprio/jason/\
genomes_indexes_references_databases/blastn_databases/vector/vector"
params.blast_contaminant_evalue = 0.001
params.blast_contaminant_outfmt = "6 qseqid stitle sseqid staxid evalue bitscore pident length"
params.blast_contaminant_log_file = "blast_contaminant.log"
params.blast_contaminant_type = "megablast"
params.blast_contaminant_max_hsphs = 1
params.blast_contaminant_max_targets = 1

//============================================================================//
// Assign resources
//============================================================================//

process {

  // Global setting
  executor = 'slurm'
  queue = 'short'
  cache = 'lenient'
  conda = "$VID/resources/virID_environment.yml"

  // Error handling
  errorStrategy = { task.exitStatus in 137..143 ? 'retry' : 'terminate' }
  maxRetries = 3

  withName: process_read_pairs {
    time = { 5.m * task.attempt }
    memory = { reads.size() < 1.GB ?
                  2.GB * task.attempt :
               reads.size() < 2.GB ?
                  5.GB * task.attempt :
               reads.size() < 3.GB ?
                  7.GB * task.attempt :
                  8.GB * task.attempt
              }
    cpus = 1
  }

  withName: spades_assembly {
    time = { paired_reads.size() + unpaired_reads.size() < 50.MB ?
                4.m * task.attempt :
             paired_reads.size() + unpaired_reads.size() < 200.MB ?
                10.m * task.attempt :
             paired_reads.size() + unpaired_reads.size() < 500.MB ?
                25.m * task.attempt :
             paired_reads.size() + unpaired_reads.size() < 1.GB ?
                50.m * task.attempt :
             paired_reads.size() + unpaired_reads.size() < 2.GB ?
                2.h * task.attempt :
                3.h * task.attempt
            }
    memory = { paired_reads.size() + unpaired_reads.size() < 1.MB ?
                  1.GB * task.attempt :
               paired_reads.size() + unpaired_reads.size() < 1.GB ?
                  10.GB * task.attempt :
                  20.GB * task.attempt
            }
    cpus = { paired_reads.size() + unpaired_reads.size() < 200.MB ?
                1 * task.attempt :
             paired_reads.size() + unpaired_reads.size() < 500.MB ?
                2 * task.attempt :
             paired_reads.size() + unpaired_reads.size() < 1.GB ?
                3 * task.attempt :
                4 * task.attempt
            }
  }

  withName: diamond {
    time = {sequences.size() < 10.KB ?
                20.m * task.attempt :
            sequences.size() < 1.MB ?
                75.m * task.attempt :
             sequences.size() < 20.MB ?
                2.h * task.attempt :
             sequences.size() < 100.MB ?
                4.h * task.attempt :
                5.h * task.attempt
            }
    memory = { 70.GB * task.attempt }
    cpus = 8
  }

  withName: convert_diamond {
    time = { assignment_file.size() < 3.MB ?
                3.m * task.attempt :
             assignment_file.size() < 6.MB ?
                6.m * task.attempt :
             assignment_file.size() < 10.MB ?
                10.m * task.attempt :
                15.m * task.attempt
            }
    memory = { 3.GB * task.attempt }
    cpus = 1
  }

  withName: blast {
    time = { sequences.size() < 10.KB ?
                5.m * task.attempt :
             sequences.size() < 50.KB ?
                10.m * task.attempt :
             sequences.size() < 500.KB ?
                20.m * task.attempt :
             sequences.size() < 1.MB ?
                30.m * task.attempt :
             sequences.size() < 10.MB ?
                1.h * task.attempt :
             sequences.size() < 20.MB ?
                2.h * task.attempt :
             sequences.size() < 40.MB ?
                3.h * task.attempt :
                4.h * task.attempt
            }
    memory = { 60.GB + 10.GB * task.attempt }
    cpus = { sequences.size() < 1.MB ?
              3 * task.attempt :
             sequences.size() < 10.MB ?
              4 * task.attempt :
              6 * task.attempt
            }
  }

  withName: convert_blast {
    time = { assignment_file.size() < 10.MB ?
                3.m * task.attempt :
             assignment_file.size() < 20.MB ?
                5.m * task.attempt :
             assignment_file.size() < 30.MB ?
                10.m * task.attempt :
                15.m * task.attempt
            }
    memory = { 4.GB * task.attempt }
    cpus = 1
  }

  withName: bwa_mem_contigs {
    time = { 8.m * task.attempt }
    memory = { 2.GB * task.attempt }
    cpus = 2
  }

  withName: blast_contaminant {
    time = { 8.m * task.attempt }
    memory = { 2.GB * task.attempt }
    cpus = 2
  }

  withName: generate_output {
    time = { task.attempt == 1 ?
                1.m :
             task.attempt == 2 ?
                10.m :
             task.attempt == 3 ?
                45.m :
                1.h
            }
    memory = { 1.GB * task.attempt }
    cpus = 1
  }

}

executor {
  // Let nextflow submit up to this many jobs in parallel at one time
  queueSize = 5000
}

report {
  enabled = true
  file = "$params.out_dir/reports/pipeline_report.html"
}

timeline {
  enabled = true
  file = "$params.out_dir/reports/timeline.html"
}

trace {
  enabled = true
  file = "$params.out_dir/reports/trace.tsv"
}

conda {
  // Where to save the conda environment so it doesn't need to be re-generated.
  cacheDir = '~/virtual_environments'
}
