//============================================================================//
// Define params
//============================================================================//

// Input and output
params.out_dir = "output"
params.reads = "raw_data/*fastq"

// SPAdes
params.spades_type = "meta"
params.temp_dir = "temp"

// DIAMOND
params.diamond_database = "/n/data2/dfci/medonc/decaprio/jason/\
genomes_indexes_references_databases/diamond_databases/ALL_SMALL80_NH.dmnd"
params.diamond_evalue = "10"
params.diamond_outfmt = "6 qseqid stitle sseqid staxids evalue bitscore pident length"

// BLAST
params.blast_database = "/n/data2/dfci/medonc/decaprio/jason/\
genomes_indexes_references_databases/blastn_databases/nt_v5/nt_v5"
params.blast_evalue = 10
params.blast_type = 'megablast'
params.blast_outfmt = "6 qseqid stitle sseqid staxid evalue bitscore pident length"
params.blast_log_file = "blast.log"
params.blast_max_hsphs = 1
params.blast_max_targets = 30
params.blast_restrict_to_taxids = ""
params.blast_ignore_taxids = ""

// BLAST/DIAMOND Conversion
params.LCA_top_percent = 1
params.within_percent_of_top_score = 1
params.taxid_blacklist = "$VID/resources/2019-08-09_blacklist.tsv"
params.diamond_readable_colnames = "query_ID seq_title seq_ID taxonID evalue bitscore pident length"
params.blast_readable_colnames = "query_ID seq_title seq_ID taxonID evalue bitscore pident length"
params.taxonomy_column = "taxonID"
params.score_column = "bitscore"

//============================================================================//
// Assign resources
//============================================================================//

process {

  // Global setting
  executor = 'slurm'
  queue = 'short'

  // Error handling
  errorStrategy = { task.exitStatus in 137..143 ? 'retry' : 'terminate' }
  maxRetries = 3

  withName: process_read_pairs {
    time = { 5.m * task.attempt }
    memory = { 3.GB * task.attempt }
    cpus = 1
  }

  withName: spades_assembly {
    time = { 60.m * task.attempt }
    memory = { 50.GB * task.attempt }
    cpus = { 3 * task.attempt }
  }

  withName: diamond {
    time = { 90.m * task.attempt }
    memory = { 50.GB * task.attempt }
    cpus = 8
  }

  withName: convert_diamond {
    time = { 15.m * task.attempt }
    memory = { 3.GB * task.attempt }
    cpus = 1
  }

  withName: blast {
    time = { 60.m * task.attempt }
    memory = 70.GB
    cpus = 5
  }

  withName: convert_blast {
    time = { 25.m * task.attempt }
    memory = { 4.GB * task.attempt }
    cpus = 1
  }

  withName: bwa_mem_contigs {
    time = { 5.m * task.attempt }
    memory = { 2.GB * task.attempt }
    cpus = 2
  }

  withName: generate_output {
    time = { 25.m * task.attempt }
    memory = { 1.GB * task.attempt }
    cpus = 1
  }

}

executor {
  // Let nextflow submit up to this many jobs in parallel at one time
  queueSize = 5000
}

report {
  enabled = true
  file = "$params.out_dir/reports/pipeline_report.html"
}

timeline {
  enabled = true
  file = "$params.out_dir/reports/timeline.html"
}

trace {
  enabled = true
  file = "$params.out_dir/reports/trace.tsv"
}
